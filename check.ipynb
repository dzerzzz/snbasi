{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprawdzenie nauczonego modelu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Użyte biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zmienne globalne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_PATH = 'check'\n",
    "\n",
    "FIRST_PHOTO = os.path.join(CHECK_PATH, \"first.jpg\")\n",
    "SECOND_PHOTO = os.path.join(CHECK_PATH, \"second.jpg\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utworzenie folderu do sprawdzenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir $CHECK_PATH"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definicja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiowanie kształtu wejścia\n",
    "input_shape = (250, 250, 3)\n",
    "\n",
    "# Definiowanie pod-sieci (ang. base network)\n",
    "def create_base_network(input_shape):\n",
    "  input = Input(shape=input_shape)\n",
    "  x = Conv2D(32, (5, 5), activation='relu')(input)\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "  x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "  x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "  x = Flatten()(x)\n",
    "  x = Dense(256, activation='relu')(x)\n",
    "  return Model(inputs=input, outputs=x)\n",
    "\n",
    "# Tworzenie pod-sieci\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "# Definiowanie wejść dla siamskiej sieci neuronowej\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# Uzyskiwanie wektorów cech z pod-sieci\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "# Funkcja Lambda do obliczenia odległości Euklidesowej między wektorami cech\n",
    "def euclidean_distance(vects):\n",
    "  x, y = vects\n",
    "  return tf.sqrt(tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "distance = Lambda(euclidean_distance, output_shape=(1,))([processed_a, processed_b])\n",
    "\n",
    "# Definiowanie modelu siamskiej sieci neuronowej\n",
    "model = Model([input_a, input_b], distance)\n",
    "\n",
    "# Kompilowanie modelu\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Wczytanie wag nauczonego modelu\n",
    "model.load_weights('model/model_1.h5')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przetworzenie obrazów wejściowych\n",
    "Najlepiej je wziąć z folderu extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funkcja do wczytania i przetworzenia obrazu\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (250, 250))  # Dostosuj rozmiar do wymagań modelu\n",
    "    img = img.astype('float32') / 255.0  # Normalizacja\n",
    "    return img\n",
    "\n",
    "# Wczytanie i przetworzenie obu zdjęć\n",
    "img1_path = FIRST_PHOTO\n",
    "img2_path = SECOND_PHOTO\n",
    "\n",
    "img1 = preprocess_image(img1_path)\n",
    "img2 = preprocess_image(img2_path)\n",
    "                        \n",
    "# plt.imshow(img1)\n",
    "\n",
    "# Utworzenie pary obrazów\n",
    "img1 = np.expand_dims(img1, axis=0)  # Dodanie wymiaru partii\n",
    "img2 = np.expand_dims(img2, axis=0)  # Dodanie wymiaru partii\n",
    "pair = [img1, img2]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predykcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Przewidywanie za pomocą modelu\n",
    "prediction = model.predict(pair)\n",
    "\n",
    "# Funkcja do oceny podobieństwa\n",
    "def is_same_person(prediction, threshold=0.5):\n",
    "    return prediction < threshold\n",
    "\n",
    "# Ocena podobieństwa\n",
    "result = is_same_person(prediction)\n",
    "print(result[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75d0c35e6bbc0220ee5b4fb051b86bfd383707c4714f3f43e0c935f3ffcd7548"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
